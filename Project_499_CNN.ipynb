{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Project_499_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NongNNew/Project_499/blob/main/Project_499_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW4AHGmEVrk8"
      },
      "source": [
        "# **CNN**"
      ],
      "id": "hW4AHGmEVrk8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkYRb02rScfH"
      },
      "source": [
        "## Setup"
      ],
      "id": "nkYRb02rScfH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq11bNFAbCci",
        "outputId": "d7a68c67-cad8-4c2e-fb78-d01b91f75ce4"
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "id": "Nq11bNFAbCci",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=38e1421c2db3e621f9f6590f87718bc9458ca19efaa869f32f73906a953198e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fssuU2ucR1vy"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import python_speech_features\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal.windows import hamming\n",
        "from sklearn.metrics import classification_report"
      ],
      "id": "fssuU2ucR1vy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1vuUlgJSKkC"
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "id": "y1vuUlgJSKkC",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRWP2IrOShCH"
      },
      "source": [
        "## Prepare dataset"
      ],
      "id": "BRWP2IrOShCH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJVdtdww87RO",
        "outputId": "0020aa76-cb42-433f-c5f3-b2f701cec6c3"
      },
      "source": [
        "# Upload audio files from github\n",
        "!git clone https://github.com/NongNNew/Project_499.git"
      ],
      "id": "gJVdtdww87RO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Project_499'...\n",
            "remote: Enumerating objects: 1456, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1456 (delta 6), reused 0 (delta 0), pack-reused 1444\u001b[K\n",
            "Receiving objects: 100% (1456/1456), 233.33 MiB | 22.33 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n",
            "Checking out files: 100% (1122/1122), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHnDUT5YejVV"
      },
      "source": [
        "# Name of vegetables and fruits 52 types of 56 classes\n",
        "fruit_veget = ['กระชาย','กระท้อน','กระเทียม1','กระเทียม2','กระเพรา','กล้วยน้ำว้า','กล้วยหอม',\n",
        "               'ข้าวโพด','ไข่น้ำ',\n",
        "               'ตะขบไทย','ตะไคร้',\n",
        "               'ถั่วฝักยาว','ถั่วลันเตา','ถั่วลิสง',\n",
        "               'ทับทิม',\n",
        "               'น้อยหน่า','น้ำเต้า',\n",
        "               'ผักกระเฉด','ผักกุยช่าย','ผักขึ้นช่าย','ผักชะอม','ผักชี','ผักชีฝรั่ง','ผักตำลึง',\n",
        "               'มะปราง','มะพลับ','มะละกอ','มะกรูด','มะเขือพวง','มะเขือเทศ','มะระ','มะรุม','มะตูม','มันแกว1','มันแกว2','มันเทศ','มันฝรั่ง','มันสำปะหลัง',\n",
        "               'บวบ','ใบชะพลู1','ใบชะพลู2','ใบบัวบก','ใบแมงลัก','ใบยอ',\n",
        "               'พริกขี้หนู','พริกสด','พุทรา','เพกา',\n",
        "               'ฝรั่ง',\n",
        "               'ฟัก','ฟักทอง',\n",
        "               'สับปะรด','สะเดา','สะระแหน่',\n",
        "               'หัวหอม1','หัวหอม2']\n",
        "\n",
        "# Audio data source\n",
        "source = {'audio_time':[],\n",
        "          'sampling_rate':[],\n",
        "          'feature_extraction':[],\n",
        "          'label':[],\n",
        "          'description':[]}"
      ],
      "id": "EHnDUT5YejVV",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XRqKtGBeW_1"
      },
      "source": [
        "def feature_mfcc(y,sr):\n",
        "    return (python_speech_features.mfcc(signal=y, \n",
        "                                    samplerate=sr, \n",
        "                                    winlen= 512/sr, \n",
        "                                    winstep= 160/sr,\n",
        "                                    numcep= 13,\n",
        "                                    nfilt= 40, \n",
        "                                    nfft= 512,\n",
        "                                    lowfreq= 0,\n",
        "                                    highfreq= None,\n",
        "                                    preemph= 0.97, \n",
        "                                    ceplifter= 0,\n",
        "                                    winfunc= hamming))"
      ],
      "id": "_XRqKtGBeW_1",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tixApnAUy5tv"
      },
      "source": [
        "for types in fruit_veget:\n",
        "    audio_files = glob('/content/Project_499/Record_audio/' + str(types) + '/*.wav')\n",
        "\n",
        "    for audio in audio_files:\n",
        "        y,sr = librosa.load(audio,duration=5,offset=0)\n",
        "        source['description'].append(str(types))\n",
        "        source['audio_time'].append(y)\n",
        "        source['sampling_rate'].append(sr)\n",
        "        source['feature_extraction'].append(feature_mfcc(y,sr))\n",
        "        source['label'].append(fruit_veget.index(types))"
      ],
      "id": "tixApnAUy5tv",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8B6cSV4Ckude",
        "outputId": "a72d46ed-20c0-4a51-824e-6567bef8a890"
      },
      "source": [
        "# tranform dictionary to dataframe \n",
        "df = pd.DataFrame.from_dict(source)\n",
        "df"
      ],
      "id": "8B6cSV4Ckude",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_time</th>\n",
              "      <th>sampling_rate</th>\n",
              "      <th>feature_extraction</th>\n",
              "      <th>label</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-9.1552734e-05, -0.00012207031, -0.0001373291...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-13.95247445826829, -10.97996817242975, 1.84...</td>\n",
              "      <td>0</td>\n",
              "      <td>กระชาย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.0002593994, -0.00022888184, -0.0002593994,...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-13.816295557200156, -10.348956209871943, 3....</td>\n",
              "      <td>0</td>\n",
              "      <td>กระชาย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.00022888184, 0.00022888184, 0.00032043457, ...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-14.045999540666703, -10.287139120802372, -0...</td>\n",
              "      <td>0</td>\n",
              "      <td>กระชาย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1.5258789e-05, -3.0517578e-05, 4.5776367e-05,...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-13.895163210723114, -10.534242113550562, 0....</td>\n",
              "      <td>0</td>\n",
              "      <td>กระชาย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.0001373291, -0.00010681152, -0.0001373291,...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-14.29427199922967, -12.51993808804879, 2.45...</td>\n",
              "      <td>0</td>\n",
              "      <td>กระชาย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>[1.5258789e-05, -4.5776367e-05, 4.5776367e-05,...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-13.862199697176345, -10.033334893928362, 0....</td>\n",
              "      <td>55</td>\n",
              "      <td>หัวหอม2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>[-0.00018310547, -0.0002593994, -0.00021362305...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-14.051788496188221, -10.373070308117175, 4....</td>\n",
              "      <td>55</td>\n",
              "      <td>หัวหอม2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117</th>\n",
              "      <td>[0.0, -3.0517578e-05, -9.1552734e-05, -9.15527...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-14.21864909518731, -10.539366597477237, 2.1...</td>\n",
              "      <td>55</td>\n",
              "      <td>หัวหอม2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>[-7.6293945e-05, -9.1552734e-05, 0.0, 1.525878...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-13.93405270581039, -11.744337964457122, 1.2...</td>\n",
              "      <td>55</td>\n",
              "      <td>หัวหอม2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>[0.0, -1.5258789e-05, 3.0517578e-05, -3.051757...</td>\n",
              "      <td>22050</td>\n",
              "      <td>[[-14.18512183869517, -10.797166196952473, 3.3...</td>\n",
              "      <td>55</td>\n",
              "      <td>หัวหอม2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1120 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             audio_time  ...  description\n",
              "0     [-9.1552734e-05, -0.00012207031, -0.0001373291...  ...       กระชาย\n",
              "1     [-0.0002593994, -0.00022888184, -0.0002593994,...  ...       กระชาย\n",
              "2     [0.00022888184, 0.00022888184, 0.00032043457, ...  ...       กระชาย\n",
              "3     [1.5258789e-05, -3.0517578e-05, 4.5776367e-05,...  ...       กระชาย\n",
              "4     [-0.0001373291, -0.00010681152, -0.0001373291,...  ...       กระชาย\n",
              "...                                                 ...  ...          ...\n",
              "1115  [1.5258789e-05, -4.5776367e-05, 4.5776367e-05,...  ...      หัวหอม2\n",
              "1116  [-0.00018310547, -0.0002593994, -0.00021362305...  ...      หัวหอม2\n",
              "1117  [0.0, -3.0517578e-05, -9.1552734e-05, -9.15527...  ...      หัวหอม2\n",
              "1118  [-7.6293945e-05, -9.1552734e-05, 0.0, 1.525878...  ...      หัวหอม2\n",
              "1119  [0.0, -1.5258789e-05, 3.0517578e-05, -3.051757...  ...      หัวหอม2\n",
              "\n",
              "[1120 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7yzW3hnmuyB"
      },
      "source": [
        "Test = pd.DataFrame(columns=source.keys())\n",
        "\n",
        "# Create test data\n",
        "for description in np.unique(df['description']):\n",
        "    imp_test = df[df['description']==description].sample(5)\n",
        "    Test = pd.concat([Test,imp_test], axis=0)\n",
        "Train = df.drop(Test.index)\n",
        "\n",
        "\n",
        "X_train = np.array(Train['feature_extraction'].to_list())\n",
        "X_test = np.array(Test['feature_extraction'].to_list())\n",
        "y_train = np.array(Train['label'].to_list())\n",
        "y_test = np.array(Test['label'].to_list())"
      ],
      "id": "T7yzW3hnmuyB",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSV3u9RmEU7h",
        "outputId": "5bf50459-c164-43f5-b830-6c2da0becac9"
      },
      "source": [
        "# Proportion of data\n",
        "y_train.shape, y_test.shape"
      ],
      "id": "mSV3u9RmEU7h",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((840,), (280,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7RGaVViSrwg"
      },
      "source": [
        "## Build cnn model"
      ],
      "id": "r7RGaVViSrwg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77wMVqve6W8f"
      },
      "source": [
        "def create_cnn_model(X_train):\n",
        "    model = None\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(128, 5, input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(keras.layers.MaxPool2D())\n",
        "    model.add(keras.layers.Conv2D(64, 5, activation='relu',padding='same'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(keras.layers.MaxPool2D())\n",
        "    model.add(keras.layers.Conv2D(64, 5, activation='relu',padding='same'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(keras.layers.MaxPool2D())\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(keras.layers.Dense(len(np.unique(df['label'])), activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "id": "77wMVqve6W8f",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_EPqJGnS7ng"
      },
      "source": [
        "## Train model"
      ],
      "id": "N_EPqJGnS7ng"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngmfDNcnGMC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ffbc0b-681c-4b77-d128-5a2a77361a3b"
      },
      "source": [
        "# Train model\n",
        "model_cnn = create_cnn_model(X_train)\n",
        "history = model_cnn.fit(X_train[:,:,:,None], y_train, epochs=100, validation_data=(X_test[:,:,:,None],y_test),batch_size=80)"
      ],
      "id": "ngmfDNcnGMC7",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 683, 9, 128)       3328      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 683, 9, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 341, 4, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 341, 4, 64)        204864    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 341, 4, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 170, 2, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 170, 2, 64)        102464    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 170, 2, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 85, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5440)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               696448    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 56)                3640      \n",
            "=================================================================\n",
            "Total params: 1,019,000\n",
            "Trainable params: 1,019,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 19s 176ms/step - loss: 4.1190 - accuracy: 0.0143 - val_loss: 4.0205 - val_accuracy: 0.0429\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 4.0076 - accuracy: 0.0250 - val_loss: 3.9798 - val_accuracy: 0.0464\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 3.8777 - accuracy: 0.0548 - val_loss: 3.8082 - val_accuracy: 0.1107\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 3.6495 - accuracy: 0.1000 - val_loss: 3.5849 - val_accuracy: 0.1786\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 3.3624 - accuracy: 0.1429 - val_loss: 3.1738 - val_accuracy: 0.3179\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 3.0146 - accuracy: 0.2060 - val_loss: 2.8815 - val_accuracy: 0.4500\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 2.4861 - accuracy: 0.3107 - val_loss: 2.6017 - val_accuracy: 0.5679\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 2.0208 - accuracy: 0.4369 - val_loss: 1.8890 - val_accuracy: 0.7143\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.7837 - accuracy: 0.5024 - val_loss: 1.7731 - val_accuracy: 0.7714\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 1.4928 - accuracy: 0.5762 - val_loss: 1.4581 - val_accuracy: 0.8071\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 1.2735 - accuracy: 0.6190 - val_loss: 1.2376 - val_accuracy: 0.8714\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 1.1763 - accuracy: 0.6548 - val_loss: 1.0956 - val_accuracy: 0.8821\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.9812 - accuracy: 0.7071 - val_loss: 1.0670 - val_accuracy: 0.9071\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.7879 - accuracy: 0.7595 - val_loss: 0.7643 - val_accuracy: 0.8929\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.7841 - accuracy: 0.7417 - val_loss: 0.7737 - val_accuracy: 0.9036\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.7332 - accuracy: 0.7440 - val_loss: 0.7243 - val_accuracy: 0.9179\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.6224 - accuracy: 0.8012 - val_loss: 0.5936 - val_accuracy: 0.9357\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.6012 - accuracy: 0.8274 - val_loss: 0.5058 - val_accuracy: 0.9286\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.5700 - accuracy: 0.8274 - val_loss: 0.5909 - val_accuracy: 0.9250\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.5850 - accuracy: 0.8155 - val_loss: 0.5422 - val_accuracy: 0.9107\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.5165 - accuracy: 0.8298 - val_loss: 0.4796 - val_accuracy: 0.9393\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.4503 - accuracy: 0.8524 - val_loss: 0.3927 - val_accuracy: 0.9500\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3828 - accuracy: 0.8667 - val_loss: 0.3823 - val_accuracy: 0.9286\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.4475 - accuracy: 0.8500 - val_loss: 0.3691 - val_accuracy: 0.9429\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3704 - accuracy: 0.8893 - val_loss: 0.3671 - val_accuracy: 0.9464\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.3427 - accuracy: 0.8786 - val_loss: 0.3157 - val_accuracy: 0.9500\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.3306 - accuracy: 0.8833 - val_loss: 0.2942 - val_accuracy: 0.9321\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3328 - accuracy: 0.8881 - val_loss: 0.2875 - val_accuracy: 0.9607\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3323 - accuracy: 0.8976 - val_loss: 0.3275 - val_accuracy: 0.9357\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2758 - accuracy: 0.9095 - val_loss: 0.3017 - val_accuracy: 0.9393\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3169 - accuracy: 0.9071 - val_loss: 0.3110 - val_accuracy: 0.9429\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3458 - accuracy: 0.8940 - val_loss: 0.3107 - val_accuracy: 0.9500\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.3064 - accuracy: 0.8976 - val_loss: 0.2489 - val_accuracy: 0.9643\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2385 - accuracy: 0.9262 - val_loss: 0.2341 - val_accuracy: 0.9464\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2298 - accuracy: 0.9226 - val_loss: 0.2364 - val_accuracy: 0.9571\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2624 - accuracy: 0.9143 - val_loss: 0.2445 - val_accuracy: 0.9679\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2225 - accuracy: 0.9274 - val_loss: 0.2321 - val_accuracy: 0.9643\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2516 - accuracy: 0.9179 - val_loss: 0.2338 - val_accuracy: 0.9571\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2628 - accuracy: 0.9131 - val_loss: 0.2301 - val_accuracy: 0.9679\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2218 - accuracy: 0.9238 - val_loss: 0.1888 - val_accuracy: 0.9714\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2218 - accuracy: 0.9321 - val_loss: 0.2113 - val_accuracy: 0.9679\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2330 - accuracy: 0.9155 - val_loss: 0.2141 - val_accuracy: 0.9607\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2023 - accuracy: 0.9405 - val_loss: 0.1938 - val_accuracy: 0.9679\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2182 - accuracy: 0.9310 - val_loss: 0.2121 - val_accuracy: 0.9679\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2504 - accuracy: 0.9226 - val_loss: 0.2060 - val_accuracy: 0.9679\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1723 - accuracy: 0.9560 - val_loss: 0.1943 - val_accuracy: 0.9786\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2011 - accuracy: 0.9345 - val_loss: 0.1772 - val_accuracy: 0.9714\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.2239 - accuracy: 0.9202 - val_loss: 0.1897 - val_accuracy: 0.9714\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.2457 - accuracy: 0.9202 - val_loss: 0.2071 - val_accuracy: 0.9679\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1595 - accuracy: 0.9524 - val_loss: 0.1805 - val_accuracy: 0.9714\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1981 - accuracy: 0.9488 - val_loss: 0.1831 - val_accuracy: 0.9714\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2060 - accuracy: 0.9357 - val_loss: 0.1717 - val_accuracy: 0.9714\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 1s 82ms/step - loss: 0.1655 - accuracy: 0.9405 - val_loss: 0.1604 - val_accuracy: 0.9750\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.2021 - accuracy: 0.9381 - val_loss: 0.1547 - val_accuracy: 0.9750\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1522 - accuracy: 0.9500 - val_loss: 0.2028 - val_accuracy: 0.9643\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1751 - accuracy: 0.9464 - val_loss: 0.1567 - val_accuracy: 0.9714\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1670 - accuracy: 0.9548 - val_loss: 0.1418 - val_accuracy: 0.9750\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1373 - accuracy: 0.9560 - val_loss: 0.1532 - val_accuracy: 0.9786\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1685 - accuracy: 0.9405 - val_loss: 0.1591 - val_accuracy: 0.9679\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1491 - accuracy: 0.9548 - val_loss: 0.1765 - val_accuracy: 0.9607\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1707 - accuracy: 0.9464 - val_loss: 0.1832 - val_accuracy: 0.9607\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1189 - accuracy: 0.9583 - val_loss: 0.1557 - val_accuracy: 0.9607\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1613 - accuracy: 0.9524 - val_loss: 0.1594 - val_accuracy: 0.9750\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1211 - accuracy: 0.9643 - val_loss: 0.1618 - val_accuracy: 0.9750\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1082 - accuracy: 0.9536 - val_loss: 0.1439 - val_accuracy: 0.9643\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1366 - accuracy: 0.9619 - val_loss: 0.1608 - val_accuracy: 0.9643\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1317 - accuracy: 0.9619 - val_loss: 0.1313 - val_accuracy: 0.9714\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1175 - accuracy: 0.9655 - val_loss: 0.1053 - val_accuracy: 0.9750\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0788 - accuracy: 0.9786 - val_loss: 0.1201 - val_accuracy: 0.9714\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0824 - accuracy: 0.9762 - val_loss: 0.1471 - val_accuracy: 0.9643\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0873 - accuracy: 0.9714 - val_loss: 0.1240 - val_accuracy: 0.9750\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1342 - accuracy: 0.9560 - val_loss: 0.1112 - val_accuracy: 0.9821\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 0.1490 - val_accuracy: 0.9786\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1128 - accuracy: 0.9631 - val_loss: 0.1100 - val_accuracy: 0.9857\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1155 - accuracy: 0.9631 - val_loss: 0.1467 - val_accuracy: 0.9714\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0924 - accuracy: 0.9655 - val_loss: 0.1215 - val_accuracy: 0.9679\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.1265 - val_accuracy: 0.9786\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.0864 - accuracy: 0.9690 - val_loss: 0.1295 - val_accuracy: 0.9607\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1365 - accuracy: 0.9631 - val_loss: 0.1143 - val_accuracy: 0.9714\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.1345 - val_accuracy: 0.9607\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1367 - accuracy: 0.9500 - val_loss: 0.1500 - val_accuracy: 0.9679\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1459 - accuracy: 0.9512 - val_loss: 0.1273 - val_accuracy: 0.9750\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1002 - accuracy: 0.9726 - val_loss: 0.1573 - val_accuracy: 0.9643\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 0.1318 - accuracy: 0.9560 - val_loss: 0.1317 - val_accuracy: 0.9643\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0891 - accuracy: 0.9750 - val_loss: 0.1552 - val_accuracy: 0.9571\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0899 - accuracy: 0.9774 - val_loss: 0.1115 - val_accuracy: 0.9714\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0793 - accuracy: 0.9762 - val_loss: 0.1301 - val_accuracy: 0.9750\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1037 - accuracy: 0.9702 - val_loss: 0.1649 - val_accuracy: 0.9607\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 0.1311 - val_accuracy: 0.9679\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1392 - accuracy: 0.9690 - val_loss: 0.1324 - val_accuracy: 0.9679\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0995 - accuracy: 0.9714 - val_loss: 0.1387 - val_accuracy: 0.9679\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1271 - accuracy: 0.9560 - val_loss: 0.1293 - val_accuracy: 0.9679\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0829 - accuracy: 0.9762 - val_loss: 0.1361 - val_accuracy: 0.9714\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1025 - accuracy: 0.9655 - val_loss: 0.1035 - val_accuracy: 0.9786\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1096 - accuracy: 0.9690 - val_loss: 0.1018 - val_accuracy: 0.9821\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0908 - accuracy: 0.9714 - val_loss: 0.0956 - val_accuracy: 0.9821\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0671 - accuracy: 0.9798 - val_loss: 0.1176 - val_accuracy: 0.9714\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0997 - accuracy: 0.9690 - val_loss: 0.1438 - val_accuracy: 0.9643\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.1191 - val_accuracy: 0.9679\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 0.0654 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_i70WoqTAxI"
      },
      "source": [
        "## Evaluate and predict test set"
      ],
      "id": "y_i70WoqTAxI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ4n8wAmB9ZX",
        "outputId": "a80f1202-b4a3-4bd5-93bc-e1be8c9b0b89"
      },
      "source": [
        "# Evaluate model\n",
        "print(f'Test Accuracy: {model_cnn.evaluate(X_test[:,:,:,None],y_test,verbose=0)[1]}')"
      ],
      "id": "ZQ4n8wAmB9ZX",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9714285731315613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62fEQaGFMqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "fa85ea86-c29d-4484-9a51-9596f5f8cda8"
      },
      "source": [
        "# Learning curve\n",
        "# plot the accuracy and loss plots between training and validation data\n",
        "# verify overfitting or underfit \n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "x = range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(x,loss,'b',label='Training loss')\n",
        "plt.plot(x,val_loss,'r',label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()"
      ],
      "id": "F62fEQaGFMqs",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4f100859d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFbKdWsMkDuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef7e62c-3287-4b11-b92d-d22099f234bd"
      },
      "source": [
        "# classification report\n",
        "predicted_classes = np.argmax(np.round(model_cnn.predict(X_test[:,:,:,None])),axis=1)\n",
        "correct = np.where(predicted_classes==y_test)[0]\n",
        "target_names = [f\"Class {label}\" for label in range(len(np.unique(df['label'])))]\n",
        "\n",
        "print(f\"From {len(y_test)} labels're founding {len(correct)} correct labels.\")\n",
        "print(f'Accuracy: {len(correct)/len(y_test)}')\n",
        "print('')\n",
        "print(classification_report(y_test, predicted_classes, target_names=target_names))"
      ],
      "id": "wFbKdWsMkDuw",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From 280 labels're founding 269 correct labels.\n",
            "Accuracy: 0.9607142857142857\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.50      1.00      0.67         5\n",
            "     Class 1       1.00      1.00      1.00         5\n",
            "     Class 2       1.00      1.00      1.00         5\n",
            "     Class 3       1.00      0.80      0.89         5\n",
            "     Class 4       0.83      1.00      0.91         5\n",
            "     Class 5       1.00      0.80      0.89         5\n",
            "     Class 6       1.00      0.80      0.89         5\n",
            "     Class 7       1.00      1.00      1.00         5\n",
            "     Class 8       1.00      1.00      1.00         5\n",
            "     Class 9       0.83      1.00      0.91         5\n",
            "    Class 10       1.00      1.00      1.00         5\n",
            "    Class 11       1.00      1.00      1.00         5\n",
            "    Class 12       1.00      1.00      1.00         5\n",
            "    Class 13       0.83      1.00      0.91         5\n",
            "    Class 14       1.00      1.00      1.00         5\n",
            "    Class 15       1.00      0.80      0.89         5\n",
            "    Class 16       1.00      1.00      1.00         5\n",
            "    Class 17       1.00      1.00      1.00         5\n",
            "    Class 18       1.00      1.00      1.00         5\n",
            "    Class 19       1.00      1.00      1.00         5\n",
            "    Class 20       1.00      1.00      1.00         5\n",
            "    Class 21       1.00      1.00      1.00         5\n",
            "    Class 22       1.00      1.00      1.00         5\n",
            "    Class 23       0.83      1.00      0.91         5\n",
            "    Class 24       1.00      1.00      1.00         5\n",
            "    Class 25       1.00      0.80      0.89         5\n",
            "    Class 26       0.83      1.00      0.91         5\n",
            "    Class 27       1.00      1.00      1.00         5\n",
            "    Class 28       1.00      1.00      1.00         5\n",
            "    Class 29       1.00      1.00      1.00         5\n",
            "    Class 30       1.00      0.80      0.89         5\n",
            "    Class 31       1.00      0.80      0.89         5\n",
            "    Class 32       1.00      1.00      1.00         5\n",
            "    Class 33       1.00      1.00      1.00         5\n",
            "    Class 34       1.00      1.00      1.00         5\n",
            "    Class 35       1.00      1.00      1.00         5\n",
            "    Class 36       1.00      1.00      1.00         5\n",
            "    Class 37       1.00      1.00      1.00         5\n",
            "    Class 38       1.00      0.80      0.89         5\n",
            "    Class 39       1.00      0.80      0.89         5\n",
            "    Class 40       1.00      1.00      1.00         5\n",
            "    Class 41       1.00      1.00      1.00         5\n",
            "    Class 42       0.83      1.00      0.91         5\n",
            "    Class 43       1.00      1.00      1.00         5\n",
            "    Class 44       1.00      1.00      1.00         5\n",
            "    Class 45       1.00      1.00      1.00         5\n",
            "    Class 46       1.00      1.00      1.00         5\n",
            "    Class 47       1.00      1.00      1.00         5\n",
            "    Class 48       1.00      0.80      0.89         5\n",
            "    Class 49       1.00      1.00      1.00         5\n",
            "    Class 50       1.00      1.00      1.00         5\n",
            "    Class 51       1.00      1.00      1.00         5\n",
            "    Class 52       1.00      0.80      0.89         5\n",
            "    Class 53       1.00      1.00      1.00         5\n",
            "    Class 54       1.00      1.00      1.00         5\n",
            "    Class 55       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.96       280\n",
            "   macro avg       0.97      0.96      0.96       280\n",
            "weighted avg       0.97      0.96      0.96       280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}