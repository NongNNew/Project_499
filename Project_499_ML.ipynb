{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_499_ML.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOkUGiGAZpF++dAdBDHRxbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NongNNew/Project_499/blob/main/Project_499_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E09RIQ3sEE0",
        "outputId": "d02fac51-ced7-4f37-9f56-a48b259e1f24"
      },
      "source": [
        "!pip install pythainlp\n",
        "!git clone https://github.com/NongNNew/Project_499.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythainlp\n",
            "  Downloading pythainlp-2.3.2-py3-none-any.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 6.6 MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading tinydb-4.5.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.5.30)\n",
            "Collecting typing-extensions<4.0.0,>=3.10.0\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions, tinydb, python-crfsuite, pythainlp\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed pythainlp-2.3.2 python-crfsuite-0.9.7 tinydb-4.5.1 typing-extensions-3.10.0.2\n",
            "Cloning into 'Project_499'...\n",
            "remote: Enumerating objects: 1553, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 1553 (delta 46), reused 93 (delta 38), pack-reused 1444\u001b[K\n",
            "Receiving objects: 100% (1553/1553), 237.68 MiB | 26.36 MiB/s, done.\n",
            "Resolving deltas: 100% (194/194), done.\n",
            "Checking out files: 100% (1144/1144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQl_FU7ux5V"
      },
      "source": [
        "from pythainlp import word_tokenize, Tokenizer, sent_tokenize ,syllable_tokenize\n",
        "from pythainlp.corpus.common import thai_words\n",
        "from pythainlp.util import dict_trie\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlrSe-DOGtpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "39e9a8a8-b156-4397-dbb6-df433447df80"
      },
      "source": [
        "df = pd.read_csv('/content/Project_499/word_segment.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thai word</th>\n",
              "      <th>native word</th>\n",
              "      <th>word1</th>\n",
              "      <th>word2</th>\n",
              "      <th>word3</th>\n",
              "      <th>word4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>กล้วยน้ำว้า</td>\n",
              "      <td>ก้วยไต้</td>\n",
              "      <td>ก้วย</td>\n",
              "      <td>ไต้</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>กล้วยหอม</td>\n",
              "      <td>ก้วยค้าว</td>\n",
              "      <td>ก้วย</td>\n",
              "      <td>ค้าว</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>กระท้อน</td>\n",
              "      <td>บ่าตื๋น</td>\n",
              "      <td>บ่า</td>\n",
              "      <td>ตื๋น</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ตะขบไทย</td>\n",
              "      <td>บ่าเกว๋นควาย</td>\n",
              "      <td>บ่า</td>\n",
              "      <td>เกว๋น</td>\n",
              "      <td>ควาย</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ทับทิม</td>\n",
              "      <td>บ่าก๊อ</td>\n",
              "      <td>บ่า</td>\n",
              "      <td>ก๊อ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     thai word   native word word1  word2 word3 word4\n",
              "0  กล้วยน้ำว้า       ก้วยไต้  ก้วย    ไต้   NaN   NaN\n",
              "1     กล้วยหอม      ก้วยค้าว  ก้วย   ค้าว   NaN   NaN\n",
              "2      กระท้อน       บ่าตื๋น   บ่า   ตื๋น   NaN   NaN\n",
              "3      ตะขบไทย  บ่าเกว๋นควาย   บ่า  เกว๋น  ควาย   NaN\n",
              "4       ทับทิม        บ่าก๊อ   บ่า    ก๊อ   NaN   NaN"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzWt6RLN9OGW"
      },
      "source": [
        "words = list()\n",
        "\n",
        "for word in df.columns[2:]:\n",
        "    words += df[word].dropna().to_list()\n",
        "\n",
        "words = dict.fromkeys(np.unique(words).tolist(),0)\n",
        "\n",
        "custom_words_list = set(thai_words())\n",
        "custom_words_list.update(words)\n",
        "trie = dict_trie(dict_source=custom_words_list)\n",
        "custom_tokenizer = Tokenizer(custom_dict=trie, engine='newmm', keep_whitespace=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAL-RqcbFhrV",
        "outputId": "fb03e58a-9640-4698-ff8f-2f20d19ec02a"
      },
      "source": [
        "text = 'อ้ายอยากกิ๋นก้วยไต้กับบ่าตื๋น'\n",
        "segment = custom_tokenizer.word_tokenize(text)\n",
        "print(segment)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['อ้าย', 'อยาก', 'กิ๋น', 'ก้วย', 'ไต้', 'กับ', 'บ่า', 'ตื๋น']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi9zmXZpCOsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b7bd73-7664-435d-aad2-b794caa0bd2d"
      },
      "source": [
        "count = list()\n",
        "for word in words:\n",
        "    num=0\n",
        "    for segment in custom_tokenizer.word_tokenize(text):\n",
        "        if segment == word:\n",
        "            num+=1\n",
        "    count.append(num)\n",
        "\n",
        "for key,values in words.items():\n",
        "    for segment in custom_tokenizer.word_tokenize(text):\n",
        "        if segment == key:\n",
        "            words[key]+=1\n",
        "\n",
        "words # words==print(words)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'กั๋บ': 0,\n",
              " 'กำ': 0,\n",
              " 'ก้วย': 1,\n",
              " 'ก้อ': 0,\n",
              " 'ก้อม': 0,\n",
              " 'ก๊อ': 0,\n",
              " 'ก๋ำ': 0,\n",
              " 'ขะ': 0,\n",
              " 'ขาว': 0,\n",
              " 'ขูด': 0,\n",
              " 'ข้าว': 0,\n",
              " 'ควาย': 0,\n",
              " 'ค้อน': 0,\n",
              " 'ค้าว': 0,\n",
              " 'จั๋ก': 0,\n",
              " 'ดิน': 0,\n",
              " 'ด่วน': 0,\n",
              " 'ตอง': 0,\n",
              " 'ตัน': 0,\n",
              " 'ตื๋น': 1,\n",
              " 'ต้าง': 0,\n",
              " 'ต๋า': 0,\n",
              " 'ถั่ว': 0,\n",
              " 'นอย': 0,\n",
              " 'นั๋ด': 0,\n",
              " 'น้อย': 0,\n",
              " 'น้ำ': 0,\n",
              " 'บั่ว': 0,\n",
              " 'บ่า': 1,\n",
              " 'ปืน': 0,\n",
              " 'ปู': 0,\n",
              " 'ป้อม': 0,\n",
              " 'ผัก': 0,\n",
              " 'ผั๋ก': 0,\n",
              " 'ผำ': 0,\n",
              " 'ผิน': 0,\n",
              " 'ฝาง': 0,\n",
              " 'พิ่ก': 0,\n",
              " 'ฟัก': 0,\n",
              " 'มะ': 0,\n",
              " 'มัน': 0,\n",
              " 'ละ': 0,\n",
              " 'ลาว': 0,\n",
              " 'ลิง': 0,\n",
              " 'ลิ่ด': 0,\n",
              " 'ลี': 0,\n",
              " 'ลู': 0,\n",
              " 'ล๋ะ': 0,\n",
              " 'สะ': 0,\n",
              " 'สา': 0,\n",
              " 'ส้ม': 0,\n",
              " 'หนอก': 0,\n",
              " 'หนอง': 0,\n",
              " 'หนุ่ม': 0,\n",
              " 'หน่อ': 0,\n",
              " 'หม่น': 0,\n",
              " 'หอม': 0,\n",
              " 'หัว': 0,\n",
              " 'ห่อย': 0,\n",
              " 'อะ': 0,\n",
              " 'เกว๋น': 0,\n",
              " 'เขือ': 0,\n",
              " 'เตียม': 0,\n",
              " 'เต้ด': 0,\n",
              " 'เป้อ': 0,\n",
              " 'เลียม': 0,\n",
              " 'เสือ': 0,\n",
              " 'แก้ว': 0,\n",
              " 'แก๋ว': 0,\n",
              " 'แค': 0,\n",
              " 'แคบ': 0,\n",
              " 'แคว้ง': 0,\n",
              " 'แดง': 0,\n",
              " 'แต้': 0,\n",
              " 'แป้น': 0,\n",
              " 'แวก': 0,\n",
              " 'แหน้': 0,\n",
              " 'แอน': 0,\n",
              " 'ใบ': 0,\n",
              " 'ไค': 0,\n",
              " 'ไต้': 1,\n",
              " 'ไม้': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}